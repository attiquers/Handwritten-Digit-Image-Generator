{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQrX_Ml-VCrf",
        "outputId": "0827e5c6-91c3-4744-b452-bff68f469bf7"
      },
      "outputs": [],
      "source": [
        "# conditional_gan_training.ipynb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "z_dim = 100 # Dimension of the noise vector\n",
        "num_classes = 10 # For MNIST digits 0-9\n",
        "image_dim = 28 * 28 # 784 for MNIST (28x28 grayscale)\n",
        "batch_size = 64\n",
        "num_epochs = 50 # Adjust as needed. Start with 50-100, observe results.\n",
        "lr = 0.0002\n",
        "b1 = 0.5 # Adam: decay of first order momentum of gradients\n",
        "b2 = 0.999 # Adam: decay of second order momentum of gradients\n",
        "\n",
        "# MNIST Dataset loading and transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "mnist_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Conditional Generator Definition\n",
        "class ConditionalGenerator(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, img_dim):\n",
        "        super().__init__()\n",
        "        # Embedding layer to convert class labels (0-9) into a dense vector\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(z_dim + num_classes, 256), # Concatenate noise and label embedding\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, img_dim),\n",
        "            nn.Tanh() # Output in range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # Ensure labels are of type torch.long for nn.Embedding\n",
        "        c = self.label_emb(labels.long())\n",
        "        input_tensor = torch.cat([noise, c], 1) # Concatenate along dimension 1 (columns)\n",
        "        return self.main(input_tensor).view(-1, 1, 28, 28) # Reshape to 1 channel, 28x28 image\n",
        "\n",
        "# Conditional Discriminator Definition\n",
        "class ConditionalDiscriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_dim):\n",
        "        super().__init__()\n",
        "        # Embedding layer for class labels\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(img_dim + num_classes, 1024), # Concatenate flattened image and label embedding\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3), # Dropout for regularization\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid() # Output a probability between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        img_flat = img.view(img.size(0), -1) # Flatten the image\n",
        "        # Ensure labels are of type torch.long for nn.Embedding\n",
        "        c = self.label_emb(labels.long())\n",
        "        input_tensor = torch.cat([img_flat, c], 1)\n",
        "        return self.main(input_tensor)\n",
        "\n",
        "# Initialize Conditional Generator and Discriminator\n",
        "generator = ConditionalGenerator(z_dim, num_classes, image_dim).to(device)\n",
        "discriminator = ConditionalDiscriminator(num_classes, image_dim).to(device)\n",
        "\n",
        "# Loss function and optimizers\n",
        "criterion = nn.BCELoss() # Binary Cross Entropy Loss for GANs\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "# Training Loop for CGAN\n",
        "print(\"Starting Conditional GAN Training Loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "        # Configure input\n",
        "        real_imgs = imgs.to(device)\n",
        "        real_labels_tensor = labels.to(device) # Labels corresponding to real images\n",
        "\n",
        "        # Adversarial ground truths (for discriminator and generator loss)\n",
        "        real_gan_labels = torch.ones(real_imgs.size(0), 1).to(device)\n",
        "        fake_gan_labels = torch.zeros(real_imgs.size(0), 1).to(device)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real images\n",
        "        output_real = discriminator(real_imgs, real_labels_tensor)\n",
        "        d_loss_real = criterion(output_real, real_gan_labels)\n",
        "\n",
        "        # Measure discriminator's ability to classify fake images\n",
        "        z = torch.randn(real_imgs.size(0), z_dim).to(device) # Noise vector\n",
        "        # Generate random labels for fake images for the discriminator's fake input\n",
        "        # This helps the discriminator learn to differentiate all types of fake digits\n",
        "        fake_labels_tensor_D = torch.randint(0, num_classes, (real_imgs.size(0),)).to(device)\n",
        "        fake_imgs = generator(z, fake_labels_tensor_D)\n",
        "\n",
        "        # Detach fake_imgs and fake_labels_tensor_D to prevent gradients from flowing to Generator\n",
        "        output_fake = discriminator(fake_imgs.detach(), fake_labels_tensor_D.detach())\n",
        "        d_loss_fake = criterion(output_fake, fake_gan_labels)\n",
        "\n",
        "        # Total discriminator loss (average of real and fake loss)\n",
        "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Generate fake images\n",
        "        z = torch.randn(real_imgs.size(0), z_dim).to(device)\n",
        "        # Generate random labels for the generator's target. The generator tries to make fake images\n",
        "        # that the discriminator will classify as 'real' with these labels.\n",
        "        gen_target_labels = torch.randint(0, num_classes, (real_imgs.size(0),)).to(device)\n",
        "        fake_imgs = generator(z, gen_target_labels)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        # The generator wants the discriminator to output '1' (real) for its fake images\n",
        "        output = discriminator(fake_imgs, gen_target_labels)\n",
        "        g_loss = criterion(output, real_gan_labels)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(dataloader)}] \"\n",
        "                f\"D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}\"\n",
        "            )\n",
        "\n",
        "    # Save generated images for visual inspection (conditional on a specific digit)\n",
        "    # This block generates 5 images of a chosen digit (e.g., '7') to see training progress.\n",
        "    if (epoch + 1) % 10 == 0 or epoch == num_epochs - 1: # Also save on the last epoch\n",
        "        with torch.no_grad():\n",
        "            test_digit = 7 # Example: generate images of digit 7\n",
        "            fixed_noise = torch.randn(5, z_dim).to(device)\n",
        "            # Create labels for the specific digit we want to generate\n",
        "            fixed_labels = torch.full((5,), test_digit, dtype=torch.long).to(device)\n",
        "            generated_images = generator(fixed_noise, fixed_labels).cpu().detach()\n",
        "\n",
        "            # Denormalize images from [-1, 1] to [0, 1] for plotting\n",
        "            generated_images = (generated_images + 1) / 2\n",
        "\n",
        "            fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
        "            for img_idx, img in enumerate(generated_images):\n",
        "                axes[img_idx].imshow(img.squeeze(), cmap='gray')\n",
        "                axes[img_idx].axis('off')\n",
        "            plt.suptitle(f'Generated Digit {test_digit} at Epoch {epoch+1}')\n",
        "            plt.show()\n",
        "\n",
        "# Save the trained generator model's state dictionary\n",
        "# This is the file you'll need  for your web app\n",
        "torch.save(generator.state_dict(), 'conditional_generator_mnist.pth')\n",
        "print(\"Training complete. Conditional Generator model saved as conditional_generator_mnist.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8EjC8HIVEiZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
